{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../chap05/dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f7a292344004>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mVideoDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVideoDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'video'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'regression'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import random\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, filenames, timesteps=10):\n",
    "        super(VideoDataset, self).__init__('video', 'regression')\n",
    "        self.set_timesteps(timesteps)\n",
    "        self.temp_red=list()\n",
    "        self.temp_blue=list()\n",
    "        self.temp_green=list()\n",
    "        xs_0=list()\n",
    "        ys_0=list()\n",
    "        xs_0_=list()\n",
    "        ys_0_temp=list()\n",
    "        xs_0_temp=list()\n",
    "        self.ext_xs = list()\n",
    "        xs_0_temp_0=list()\n",
    "        xs_0_extra=list()\n",
    "        #print(xs_0)\n",
    "        list_Total=['A','T','G','C']\n",
    "        for i in range(10): #무작위로 AsCpf1 정답값 생성\n",
    "            list_target=random.randint(10,35) #10~35 사이 정수 값 생성\n",
    "            ys_0.append(list_target)\n",
    "            \n",
    "        for i in range(10):  #무작위로 10개 데이터셋 생성\n",
    "            list_ran=[]\n",
    "            for j in range(34):  #34개 A,T,G,C 무작위로 뽑기\n",
    "                list_ran.append(random.choice(list_Total))\n",
    "            xs_0.append(list_ran)   #최종결과는 2차원 리스트, 차원 크기는 [10, 34]   10은 데이터 개수, 34는 34열 시계열 정보\n",
    "            \n",
    "        for i in range(10):  # 10개 데이터셋 one hot vecter로 만들기\n",
    "            list_ran=[]\n",
    "            for j in range(34):  #34개 A,T,G,C에 대하여 각각 원햇 벡터 형태로 변환하기.\n",
    "                if j >=4 or j<28: #중간 24bp 만큼 처리\n",
    "                    if 'A' == xs_0[i][j]:\n",
    "                        list_ran.append([1,0,0,0])\n",
    "                    elif 'T' == xs_0[i][j]:\n",
    "                        list_ran.append([0,1,0,0])\n",
    "                    elif 'G' == xs_0[i][j]:\n",
    "                        list_ran.append([0,0,1,0])\n",
    "                    else:\n",
    "                        list_ran.append([0,0,0,1])\n",
    "                    \n",
    "            xs_0_.append(list_ran)   #최종결과는 2차원 리스트, 차원 크기는 [10, 34, 4]   10은 데이터 개수, \n",
    "                                     #34는 34열 시계열 정보 34는 원햇벡터 차원 크기\n",
    "        \n",
    "        for i in range(10):  # 10개 데이터셋 chromatin accessibility 무작위 생성\n",
    "            list_target=random.randint(100,350) #100~350 사이 정수 값 생성\n",
    "            xs_0_extra.append(list_target)\n",
    "                    \n",
    "    \n",
    "        \n",
    "        xs_0_=np.array(xs_0_,dtype=np.float32) #넘비 배열로 형 변환\n",
    "        xs_0_extra=np.array(xs_0_extra,dtype=np.float32)\n",
    "        self.xs_0_extra=xs_0_extra.reshape((10,1))\n",
    "        ys_0=np.array(ys_0,dtype=np.float32)\n",
    "        ys_0=ys_0.reshape((10,1))\n",
    "        \n",
    "        print(\"xs_0_\",xs_0_.shape)#xs_0_ (10, 34, 4)\n",
    "        print(\"ys_0\",ys_0.shape) #ys_0 (10, 1)\n",
    "        \n",
    "        self.divide_data(xs_0_, ys_0, 0.7) # 학습 데이터, 테스트 데이터 분할\n",
    "        \n",
    "    def set_timesteps(self, timesteps):\n",
    "        self.timesteps = timesteps\n",
    "        self.input_shape = [timesteps+1, 100, 200, 3] #이미지 개수\n",
    "        self.output_shape = [timesteps+1, 2] #출력 2개의 속력\n",
    "        \n",
    "    @property\n",
    "    def train_count(self):\n",
    "        return len(self.tr_xs)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({}, {} train_data)'.format(self.name, self.mode, self.train_count)\n",
    "    \n",
    "    def get_train_data(self, batch_size, nth): #학습할때 사용될 데이터를 불러오는 함수입니다.\n",
    "        from_idx = nth * batch_size        #배치사이즈 개수만큼 데이터를 긁어오기 위해 번호를 만듭니다.\n",
    "        to_idx = (nth + 1) * batch_size\n",
    "        tr_X = self.tr_xs[self.indices[from_idx:to_idx]]    # self.indices 함수는 1번부터 데이터개수만큼\n",
    "        tr_Y = self.tr_ys[self.indices[from_idx:to_idx]]    # 넘버링된 값이 무작위로 정렬되어있는 함수입니다.\n",
    "        return tr_X, tr_Y                                   # 거기에 적힌 번호의 데이터를 가져와서 출력해줍니다.\n",
    "\n",
    "    def shuffle_train_data(self, size):  #self.indices 함수를 만드는 과정입니다.\n",
    "        np.random.seed(int(time.time()))\n",
    "        self.indices = np.arange(size)\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    def get_test_data(self):            #테스트 데이터를 불러오는 함수입니다.\n",
    "        return self.te_xs, self.te_ys\n",
    "\n",
    "    def divide_data(self, xs, ys, tr_ratio=0.7):  #학습 데이터 테스트 데이터 분할하는 함수입니다.\n",
    "        data_count = 10  #총 10개\n",
    "        tr_cnt = data_count * tr_ratio  #개수를 나눕니다.\n",
    "        te_cnt = data_count - (tr_cnt)\n",
    "\n",
    "        tr_from, tr_to = 0, tr_cnt\n",
    "        te_from, te_to = tr_cnt, data_count\n",
    "        print(\"divide_data,data_count,tr_from,tr_to,te_to\",data_count,tr_from,tr_to,te_to)\n",
    "        self.tr_xs = xs[tr_from:tr_to]   #여기서부터 저기까지 학습데이터,\n",
    "        self.tr_ys = ys[tr_from:tr_to]   #여기서부터 저기까지 학습될 타겟 데이터\n",
    "        self.te_xs = xs[te_from:te_to]   #여기서부터 저기까지 테스트 데이터\n",
    "        self.te_ys = ys[te_from:te_to]   #여기서부터 저기까지 테스트 타겟 데이터\n",
    "        self.ext_training_xs = self.xs_0_extra[tr_from:tr_to]  #여기서부터 저기까지 학습될 chromatin accessbility input\n",
    "        self.ext_test_xs = self.xs_0_extra[te_from:te_to] #여기서부터 저기까지 테스트 chromatin accessbility input\n",
    "        #print(self.tr_xs, self.te_xs)\n",
    "        \n",
    "        self.input_shape = xs[0].shape\n",
    "        self.output_shape = ys[0].shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_shot_forward_postproc(self, output, y):\n",
    "    diff = output - y\n",
    "    square = np.square(diff)\n",
    "    loss = np.mean(square[:,:])\n",
    "    aux = diff\n",
    "\n",
    "    return loss, aux\n",
    "\n",
    "def video_shot_backprop_postproc(self, G_loss, aux):\n",
    "    diff = aux\n",
    "    shape = diff.shape\n",
    "\n",
    "    g_loss_square = np.ones(shape) / np_cpu.prod(shape)\n",
    "    g_square_diff = 2 * diff\n",
    "    g_diff_output = 1\n",
    "\n",
    "    G_square = g_loss_square * G_loss\n",
    "    G_diff = g_square_diff * G_square\n",
    "    G_output = g_diff_output * G_diff\n",
    "\n",
    "    return G_output\n",
    "\n",
    "VideoDataset.forward_postproc = video_shot_forward_postproc\n",
    "VideoDataset.backprop_postproc = video_shot_backprop_postproc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
